{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clust.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romanzes637/tensor/blob/master/clust.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usZ09rTD-1B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knk_jDNm_Hck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "paths = ['/gdrive/My Drive/Colab Notebooks/tube10El/{}/devStr'.format(x) for x in range(1, 35)]\n",
        "times = list()\n",
        "ts= list()\n",
        "# initial state\n",
        "# ts.append(np.zeros((n, 6)))\n",
        "# times.append(np.full(n, 0))\n",
        "# other steps\n",
        "m = 0\n",
        "n = 16000\n",
        "for i, p in enumerate(paths):\n",
        "  with open(p) as f:\n",
        "    lines = f.readlines()\n",
        "    x = np.array([[float(y) for y in x.strip()[1:-1].split()] for x in lines[18:-5]])[m:m+n]\n",
        "    ts.append(x)\n",
        "    times.append(np.full(len(x), i + 1))\n",
        "ts = np.vstack(ts)\n",
        "times = np.hstack(times)\n",
        "print(len(ts), ts[0], ts[-1])\n",
        "print(len(times), times[0], times[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZj5CSUImPhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tensor_sort(t):\n",
        "  at_map = {\n",
        "      (1, 2): 3, (2, 1): 3,\n",
        "      (0, 2): 4, (2, 0): 4,\n",
        "      (0, 1): 5, (1, 0): 5\n",
        "  }\n",
        "  st = t[:3]\n",
        "  sort_st = np.argsort(-np.abs(st))\n",
        "  ind = np.array([sort_st[0], \n",
        "                  sort_st[1], \n",
        "                  sort_st[2], \n",
        "                  at_map[(sort_st[0], sort_st[1])],\n",
        "                  at_map[(sort_st[1], sort_st[2])],\n",
        "                  at_map[(sort_st[2], sort_st[0])]])\n",
        "  new_t = t[ind]\n",
        "  return new_t\n",
        "def tensors_stat(ts):\n",
        "  stat = dict()\n",
        "  for t in ts:\n",
        "    tt = tuple(t)\n",
        "    stat[tt] = stat.get(tt, 0) + 1\n",
        "  return stat\n",
        "   \n",
        "def tensors_groups(ts, ndigits=2):\n",
        "  groups = dict()\n",
        "  for i, t in enumerate(ts): \n",
        "    tt = tuple(round(x, ndigits) for x in t)\n",
        "    groups.setdefault(tt, list()).append(i)\n",
        "  map_tensor_group = dict()\n",
        "  for gi, (k, v) in enumerate(groups.items()):\n",
        "    for ti in v:\n",
        "      map_tensor_group[ti] = gi\n",
        "  return groups, map_tensor_group\n",
        "\n",
        "# t = np.array([1, 2, -3, 2, 0, 1])\n",
        "# tensor_sort(t)\n",
        "# ts = np.array([\n",
        "#     [1, 2, -3, 2, 0, 1],\n",
        "#     [1, 2, -3, 2, 0, 1]\n",
        "# ])\n",
        "# print(ts)\n",
        "# ts = np.apply_along_axis(tensor_sort, 1, ts)\n",
        "# print(ts)\n",
        "# ts = np.apply_along_axis(\n",
        "#     lambda x: x / max(np.abs(x)) if max(np.abs(x)) != 0 else x, 1, ts)\n",
        "# print(ts)\n",
        "# tensors_group(ts, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOVbMHnC5COT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort tensors (max, int, min, max-int, int-min, min-max)\n",
        "X = ts.copy()\n",
        "print(len(X))\n",
        "print(X[-1])\n",
        "X = np.apply_along_axis(tensor_sort, 1, X)\n",
        "print(X[-1])\n",
        "print(ts[-1])\n",
        "# Normalize to interval [-1, 1]\n",
        "X = np.apply_along_axis(\n",
        "    lambda x: x / max(np.abs(x)) if max(np.abs(x)) != 0 else x, 1, X)\n",
        "print(X[-1])\n",
        "# Normalize to distinct: -1, 0 and 1, 0.5, -0.5\n",
        "X2 = X.copy()\n",
        "# print(X[-1])\n",
        "# print(X2[-1])\n",
        "# X2[(X2 > -1e-3) & (X2 < 1e-3)] = 0\n",
        "# # X2[(X2 > 0) & (X2 <= 0.5)] = 0.5\n",
        "# # X2[(X2 < 0) & (X2 >= -0.5)] = -0.5\n",
        "# # X2[(X2 > 0.5)] = 1\n",
        "# # X2[(X2 < -0.5)] = -1\n",
        "# X2[X2 > 0] = 1\n",
        "# X2[X2 < 0] = -1\n",
        "# print(X[-1])\n",
        "# print(X2[-1])\n",
        "# Groups of identical tensors\n",
        "gs, map_tg = tensors_groups(X, 3)\n",
        "print(len(gs))\n",
        "# print(gs)\n",
        "X3 = np.array(list(gs))\n",
        "# print(X3)\n",
        "# Evaluate distinct categories\n",
        "X3D = X3.copy()\n",
        "X3D[(X3D > -1e-3) & (X3D < 1e-3)] = 0\n",
        "# X3D[(X3D > 0) & (X3D <= 0.5)] = 0.5\n",
        "# X3D[(X3D < 0) & (X3D >= -0.5)] = -0.5\n",
        "# X3D[(X3D > 0.5)] = 1\n",
        "# X3D[(X3D < -0.5)] = -1\n",
        "X3D[X3D > 0] = 1\n",
        "X3D[X3D < 0] = -1\n",
        "print(X3D[-1])\n",
        "x3d_gs, x3d_tg = tensors_groups(X3D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ziwAUiJBN0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.ticker import NullFormatter\n",
        "\n",
        "from sklearn import manifold, datasets, preprocessing\n",
        "\n",
        "style.use('default')\n",
        "# Next line to silence pyflakes. This import is needed.\n",
        "Axes3D  \n",
        "\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "n_points = len(X3)\n",
        "n_neighbors = 10\n",
        "n_components = 2\n",
        "# plt.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n",
        "#              % (n_points, n_neighbors), fontsize=14)\n",
        "# color = np.array([x3d_tg[i] for i, _ in enumerate(X3)])\n",
        "color = np.ones(len(X3))  # black\n",
        "\n",
        "\n",
        "# ax = fig.add_subplot(251, projection='3d')\n",
        "# ax.scatter(X3[:, 0], X3[:, 1], X3[:, 2], c=color, cmap=plt.cm.Spectral)\n",
        "# ax.view_init(4, -72)\n",
        "\n",
        "methods = ['standard', 'ltsa', 'hessian', 'modified']\n",
        "labels = ['LLE', 'LTSA', 'Hessian LLE', 'Modified LLE']\n",
        "\n",
        "YS = list()\n",
        "for i, method in enumerate(methods):\n",
        "    t0 = time()\n",
        "    Y = manifold.LocallyLinearEmbedding(n_neighbors, n_components,\n",
        "                                        eigen_solver='auto',\n",
        "                                        method=method).fit_transform(X3)\n",
        "    t1 = time()\n",
        "    print(\"%s: %.2g sec\" % (methods[i], t1 - t0))\n",
        "\n",
        "    ax = fig.add_subplot(241 + i)\n",
        "    plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.gray)\n",
        "#     plt.title(\"%s (%.2g sec)\" % (labels[i], t1 - t0))\n",
        "    plt.title(\"%s\" % (labels[i]))\n",
        "    ax.xaxis.set_major_formatter(NullFormatter())\n",
        "    ax.yaxis.set_major_formatter(NullFormatter())\n",
        "    plt.axis('tight')\n",
        "    YS.append(Y)\n",
        "\n",
        "t0 = time()\n",
        "Y_iso = manifold.Isomap(n_neighbors, n_components).fit_transform(X3)\n",
        "t1 = time()\n",
        "print(\"Isomap: %.2g sec\" % (t1 - t0))\n",
        "ax = fig.add_subplot(245)\n",
        "plt.scatter(Y_iso[:, 0], Y_iso[:, 1], c=color, cmap=plt.cm.gray)\n",
        "plt.title(\"Isomap\")\n",
        "# plt.title(\"Isomap (%.2g sec)\" % (t1 - t0))\n",
        "ax.xaxis.set_major_formatter(NullFormatter())\n",
        "ax.yaxis.set_major_formatter(NullFormatter())\n",
        "plt.axis('tight')\n",
        "\n",
        "\n",
        "t0 = time()\n",
        "mds = manifold.MDS(n_components, max_iter=100, n_init=1)\n",
        "Y_mds = mds.fit_transform(X3)\n",
        "t1 = time()\n",
        "print(\"MDS: %.2g sec\" % (t1 - t0))\n",
        "ax = fig.add_subplot(246)\n",
        "plt.scatter(Y_mds[:, 0], Y_mds[:, 1], c=color, cmap=plt.cm.gray)\n",
        "plt.title(\"MDS\")\n",
        "# plt.title(\"MDS (%.2g sec)\" % (t1 - t0))\n",
        "ax.xaxis.set_major_formatter(NullFormatter())\n",
        "ax.yaxis.set_major_formatter(NullFormatter())\n",
        "plt.axis('tight')\n",
        "\n",
        "\n",
        "t0 = time()\n",
        "se = manifold.SpectralEmbedding(n_components=n_components,\n",
        "                                n_neighbors=n_neighbors)\n",
        "Y_se = se.fit_transform(X3)\n",
        "t1 = time()\n",
        "print(\"SpectralEmbedding: %.2g sec\" % (t1 - t0))\n",
        "ax = fig.add_subplot(247)\n",
        "plt.scatter(Y_se[:, 0], Y_se[:, 1], c=color, cmap=plt.cm.gray)\n",
        "plt.title(\"SpectralEmbedding\")\n",
        "# plt.title(\"SpectralEmbedding (%.2g sec)\" % (t1 - t0))\n",
        "ax.xaxis.set_major_formatter(NullFormatter())\n",
        "ax.yaxis.set_major_formatter(NullFormatter())\n",
        "plt.axis('tight')\n",
        "\n",
        "t0 = time()\n",
        "tsne = manifold.TSNE(n_components=n_components, init='pca', random_state=0)\n",
        "Y_tsne = tsne.fit_transform(X3)\n",
        "t1 = time()\n",
        "print(\"t-SNE: %.2g sec\" % (t1 - t0))\n",
        "ax = fig.add_subplot(248)\n",
        "plt.scatter(Y_tsne[:, 0], Y_tsne[:, 1], c=color, cmap=plt.cm.gray)\n",
        "plt.title(\"t-SNE\")\n",
        "# plt.title(\"t-SNE (%.2g sec)\" % (t1 - t0))\n",
        "ax.xaxis.set_major_formatter(NullFormatter())\n",
        "ax.yaxis.set_major_formatter(NullFormatter())\n",
        "plt.axis('tight')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAc2peyUwQa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.ticker import NullFormatter\n",
        "\n",
        "from sklearn import manifold, datasets, preprocessing\n",
        "\n",
        "# Next line to silence pyflakes. This import is needed.\n",
        "Axes3D  \n",
        "\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "update = True\n",
        "name = 'test2'\n",
        "if update:  # rate is about of 10000 points/sec\n",
        "  n_points = len(X3)\n",
        "  print(n_points)\n",
        "  n_neighbors = 10\n",
        "  n_components = 2\n",
        "\n",
        "  t0 = time()\n",
        "  tsne = manifold.TSNE(n_components=n_components, \n",
        "                       perplexity=50.,\n",
        "                       early_exaggeration=12.,\n",
        "                       learning_rate=200.,\n",
        "                       init='random',\n",
        "                       n_iter=1000,\n",
        "                       verbose=1,\n",
        "                       method='barnes_hut',\n",
        "                       random_state=None)\n",
        "  Y4S = tsne.fit_transform(X3)\n",
        "  t1 = time()\n",
        "  print(\"t-SNE: %.2g sec\" % (t1 - t0))\n",
        "  # plt.title(\"t-SNE (%.2g sec)\" % (t1 - t0))\n",
        "  np.save('/gdrive/My Drive/Colab Notebooks/Y4S_{}'.format(name), Y4S)\n",
        "  Y4 = np.array([Y4S[map_tg[i]] for i, _ in enumerate(X)])\n",
        "  np.save('/gdrive/My Drive/Colab Notebooks/Y4_{}'.format(name), Y4)\n",
        "  np.save('/gdrive/My Drive/Colab Notebooks/X_{}'.format(name), X)\n",
        "  np.save('/gdrive/My Drive/Colab Notebooks/X2_{}'.format(name), X2)\n",
        "  np.save('/gdrive/My Drive/Colab Notebooks/X3_{}'.format(name), X3)\n",
        "  np.save('/gdrive/My Drive/Colab Notebooks/ts_{}'.format(name), ts)\n",
        "  np.save('/gdrive/My Drive/Colab Notebooks/times_{}'.format(name), times)\n",
        "  with open('/gdrive/My Drive/Colab Notebooks/groups_{}.pickle'.format(name), 'wb') as f:\n",
        "    pickle.dump(gs, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  with open('/gdrive/My Drive/Colab Notebooks/map_tg_{}.pickle'.format(name), 'wb') as f:\n",
        "    pickle.dump(map_tg, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  with open('/gdrive/My Drive/Colab Notebooks/x3d_gs_{}.pickle'.format(name), 'wb') as f:\n",
        "    pickle.dump(x3d_gs, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  with open('/gdrive/My Drive/Colab Notebooks/x3d_tg_{}.pickle'.format(name), 'wb') as f:\n",
        "    pickle.dump(x3d_tg, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "else:\n",
        "  print('loading')\n",
        "  Y4 = np.load('/gdrive/My Drive/Colab Notebooks/Y4_{}.npy'.format(name))\n",
        "  Y4S = np.load('/gdrive/My Drive/Colab Notebooks/Y4S_{}.npy'.format(name))\n",
        "  X = np.load('/gdrive/My Drive/Colab Notebooks/X_{}.npy'.format(name))\n",
        "  X2 = np.load('/gdrive/My Drive/Colab Notebooks/X2_{}.npy'.format(name))\n",
        "  X3 = np.load('/gdrive/My Drive/Colab Notebooks/X3_{}.npy'.format(name))\n",
        "  ts = np.load('/gdrive/My Drive/Colab Notebooks/ts_{}.npy'.format(name))\n",
        "  times = np.load('/gdrive/My Drive/Colab Notebooks/times_{}.npy'.format(name))\n",
        "  with open('/gdrive/My Drive/Colab Notebooks/groups_{}.pickle'.format(name), 'rb') as f:\n",
        "    gs = pickle.load(f)\n",
        "  with open('/gdrive/My Drive/Colab Notebooks/map_tg_{}.pickle'.format(name), 'rb') as f:\n",
        "    map_tg = pickle.load(f)\n",
        "  with open('/gdrive/My Drive/Colab Notebooks/x3d_gs_{}.pickle'.format(name), 'rb') as f:\n",
        "    x3d_gs = pickle.load(f)\n",
        "  with open('/gdrive/My Drive/Colab Notebooks/x3d_tg_{}.pickle'.format(name), 'rb') as f:\n",
        "    x3d_tg = pickle.load(f)\n",
        "print(Y4.shape)\n",
        "# Colors\n",
        "# print(color[-1])\n",
        "# color = color / max(color)\n",
        "# print(color[-1])\n",
        "scolor = np.array([x3d_tg[i] for i, _ in enumerate(X3)])\n",
        "# print(scolor[1])\n",
        "# ax = fig.add_subplot(2, 5, 10)\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "plt.scatter(Y4S[:, 0], Y4S[:, 1], c=scolor, cmap=plt.cm.tab10)\n",
        "# plt.scatter(Y4[:, 0], Y4[:, 1], c=color, cmap=plt.cm.viridis)\n",
        "# start = 30000\n",
        "# end = 35001\n",
        "# plt.scatter(Y4[start:end, 0], Y4[start:end, 1], c=color[start:end], cmap=plt.cm.viridis)\n",
        "# ax.set_facecolor('black')\n",
        "ax.xaxis.set_major_formatter(NullFormatter())\n",
        "ax.yaxis.set_major_formatter(NullFormatter())\n",
        "ax.set_aspect('equal')\n",
        "plt.tight_layout()\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmJgCrsSMHZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from itertools import cycle, islice\n",
        "from ipywidgets import interact, interactive, interact_manual\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "YC = Y4S\n",
        "labels = [0 for x in YC]\n",
        "def clusterize(eps=3., min_samples=2):\n",
        "  clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(YC)\n",
        "  global labels \n",
        "  labels = clustering.labels_.astype(np.int)\n",
        "  labels = [x + 1 for x in labels]\n",
        "#   print(len(y_pred), len(Y_mds))\n",
        "  print(set(labels))\n",
        "#   colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n",
        "#                                        '#f781bf', '#a65628', '#984ea3',\n",
        "#                                        '#999999', '#e41a1c', '#dede00']),\n",
        "#                                         int(max(labels) + 1))))\n",
        "#   add black color for outliers (if any)\n",
        "#   colors = np.append(colors, [\"#000000\"])\n",
        "  plt.figure(figsize=(5, 5))\n",
        "#   plt.scatter(YC[:, 0], YC[:, 1], s=10, color=colors[labels])\n",
        "  plt.scatter(YC[:, 0], YC[:, 1], s=10, c=labels, cmap=plt.cm.tab10)\n",
        "  ax.set_aspect('equal')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  return labels\n",
        "\n",
        "p = interactive(clusterize, eps=(0, 100, .05), min_samples=(1, 100, 1))\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr6JVkrJK3d5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "groups = [' | '.join(map('{}'.format, x)) for x in x3d_gs]\n",
        "kind = np.array([groups[x3d_tg[i]] for i, _ in enumerate(X3)])\n",
        "cnt = np.array([len(x) for x in gs.values()])\n",
        "clusters_tensors = dict()\n",
        "for i, label in enumerate(labels):\n",
        "  clusters_tensors.setdefault(label, list()).append(i)\n",
        "clusters_means = dict()\n",
        "for k, v in clusters_tensors.items():\n",
        "  ts = [X3[x] for x in v]\n",
        "  m = np.mean(ts, axis=0)\n",
        "  clusters_means[k] = ' | '.join(map('{: .2f}'.format, m))\n",
        "clusters = ['{:{align}{width}}. '.format(x, align='>', width='3') + clusters_means[x] for i, x in enumerate(labels)]\n",
        "tags = ['tag_{}'.format(i) for i, _ in enumerate(Y4S)]\n",
        "df = pd.DataFrame({'x': Y4S[:, 0], 'y': Y4S[:, 1], 'kind': kind, 'cnt': cnt,\n",
        "                   'cluster': clusters, 'tag': tags,\n",
        "                   '11': X3[:, 0], '22': X3[:, 1], '33': X3[:, 2],\n",
        "                   '12': X3[:, 3], '23': X3[:, 4], '13': X3[:, 5]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KfzjUVbLZH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import altair as alt\n",
        "alt.data_transformers.enable(max_rows=None)\n",
        "alt.renderers.set_embed_options(theme='Default')  # 'Default'\n",
        "\n",
        "interval = alt.selection_interval(\n",
        "  zoom=False,\n",
        "  on='[mousedown[event.button === 0], window:mouseup] > window:mousemove!'\n",
        "#   clear='[mousedown[event.button === 2], window:mouseup] > window:mousemove!'\n",
        ")\n",
        "scale = alt.selection_interval(\n",
        "  bind='scales', \n",
        "  translate='[mousedown[event.button === 1], window:mouseup] > window:mousemove!')\n",
        "size = 350\n",
        "\n",
        "# dropdown = alt.binding_select(options=groups)\n",
        "# selection = alt.selection_single(fields=['kind'], bind=dropdown, name='kind')\n",
        "\n",
        "points = alt.Chart(width=size, height=size).transform_calculate(\n",
        "    url='https://www.google.com/search?q=' + alt.datum.cnt\n",
        ").mark_circle().encode(\n",
        "  alt.X('x:Q', axis=alt.Axis(title='', grid=False)),\n",
        "  alt.Y('y:Q', axis=alt.Axis(title='', grid=False)),\n",
        "  color=alt.condition(interval, alt.Color(\n",
        "      'cluster:N', legend=alt.Legend(labelLimit=200), sort=None), alt.value('lightgrey')),\n",
        "  size='cnt:Q',\n",
        "  href='url:N',\n",
        "  tooltip=['cnt:Q', '11:N', '22:N', '33:N', '12:N', '23:N', '13:N', \n",
        "           'cluster:N', 'tag:N', 'url:N']\n",
        ").add_selection(\n",
        "    scale,\n",
        "    interval)\n",
        "#     selection\n",
        "# ).transform_filter(selection)\n",
        "\n",
        "bar = alt.Chart().transform_filter(interval).transform_aggregate(\n",
        "    mn11 = 'mean(11)', md11 = 'median(11)',\n",
        "    mn22 = 'mean(22)', md22 = 'median(22)',\n",
        "    mn33 = 'mean(33)', md33 = 'median(33)',\n",
        "    mn12 = 'mean(12)', md12 = 'median(12)',\n",
        "    mn23 = 'mean(23)', md23 = 'median(23)',\n",
        "    mn13 = 'mean(13)', md13 = 'median(13)'\n",
        ").transform_fold(['mn11', 'md11', 'mn22', 'md22', 'mn33', 'md33',\n",
        "                  'mn12', 'md12', 'mn23', 'md23', 'mn13', 'md13']).mark_bar(\n",
        "    stroke='transparent').encode(\n",
        "    x=alt.X('key:N', axis=alt.Axis(title='component'), \n",
        "            sort=['mn11', 'md11', 'mn22', 'md22', 'mn33', 'md33',\n",
        "                  'mn12', 'md12', 'mn23', 'md23', 'mn13', 'md13']),\n",
        "    y=alt.Y('value:Q', axis=alt.Axis(title='mean, median'),\n",
        "            scale=alt.Scale(domain=(-1, 1))),\n",
        "    tooltip=['mn11:Q', 'md11:Q', 'mn22:Q', 'md22:Q', 'mn33:Q', 'md33:Q',\n",
        "             'mn12:Q', 'md12:Q', 'mn23:Q', 'md23:Q', 'mn13:Q', 'md13:Q']\n",
        "#     color=alt.Color('key:N', legend=None, scale=alt.Scale(\n",
        "#         scheme=alt.SchemeParams(name='dark2', count=2))),\n",
        "    ).properties(height=100, width=size)\n",
        "\n",
        "text = alt.Chart().mark_text(dy=-60).encode(text='sum(cnt):Q').transform_filter(interval)\n",
        "\n",
        "tensors = alt.vconcat(points, bar + text, data=df)\n",
        "\n",
        "tensors.save('/gdrive/My Drive/Colab Notebooks/tensors.html')\n",
        "tensors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9dthKIBKEKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, style, cm\n",
        "style.use('dark_background')\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "cmap = cm.get_cmap('viridis')\n",
        "colors = cmap(color)\n",
        "def draw_3d_update(frame, m, n):\n",
        "  d = 3\n",
        "  i = int(frame / m)\n",
        "  k = frame / m - i\n",
        "  prev_start = i * n\n",
        "  prev_end = i * n + n\n",
        "  start = (i + 1) * n\n",
        "  end = (i + 1) * n + n\n",
        "  if end > len(Y4):\n",
        "    start = prev_start\n",
        "    end = prev_end\n",
        "  print(n, m, i, i + 1, prev_start, prev_end, start, end, k)\n",
        "  cs = colors[start:end]\n",
        "  ps = Y4[start:end]\n",
        "  prev_ps = Y4[prev_start:prev_end]\n",
        "  prev_cs = colors[prev_start:prev_end]\n",
        "  delta_ps = ps - prev_ps\n",
        "  delta_cs = cs - prev_cs\n",
        "  cur_ps = prev_ps + k * delta_ps\n",
        "  cur_cs = prev_cs + k * delta_cs\n",
        "  ax.cla()\n",
        "  ax.scatter(cur_ps[:, 0], cur_ps[:, 1], s=1**2, c=cur_cs)\n",
        "  ax.set_xlim(min(Y4[:, 0]) - d, max(Y4[:, 0]) + d)\n",
        "  ax.set_ylim(min(Y4[:, 1]) - d, max(Y4[:, 1]) + d)\n",
        "#   ax.set_xlim(-6.5, -2)\n",
        "#   ax.set_ylim(1, 5.5)\n",
        "# ax.xaxis.set_major_formatter(NullFormatter())\n",
        "# ax.yaxis.set_major_formatter(NullFormatter())\n",
        "  ax.set_aspect('equal')\n",
        "  plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "steps = 35\n",
        "m = 5\n",
        "n = 16000\n",
        "ani = animation.FuncAnimation(fig, draw_3d_update, (steps - 1)*m + 1, \n",
        "                              fargs=[m, n], interval=200, blit=False)\n",
        "ani.save('/gdrive/My Drive/Colab Notebooks/test2.gif', writer='imagemagick')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeZ89ivs1SgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "\n",
        "from sklearn import cluster, datasets, mixture\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import cycle, islice\n",
        "\n",
        "style.use('default')\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# ============\n",
        "# Generate datasets. We choose the size big enough to see the scalability\n",
        "# of the algorithms, but not too big to avoid too long running times\n",
        "# ============\n",
        "n_samples = 1500\n",
        "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5,\n",
        "                                      noise=.05)\n",
        "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
        "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
        "no_structure = np.random.rand(n_samples, 2), None\n",
        "\n",
        "# Anisotropicly distributed data\n",
        "random_state = 170\n",
        "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
        "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "X_aniso = np.dot(X, transformation)\n",
        "aniso = (X_aniso, y)\n",
        "\n",
        "# blobs with varied variances\n",
        "varied = datasets.make_blobs(n_samples=n_samples,\n",
        "                             cluster_std=[1.0, 2.5, 0.5],\n",
        "                             random_state=random_state)\n",
        "\n",
        "# ============\n",
        "# Set up cluster parameters\n",
        "# ============\n",
        "plt.figure(figsize=(10*4, 8*4))\n",
        "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
        "                    hspace=.01)\n",
        "\n",
        "plot_num = 1\n",
        "\n",
        "default_base = {'quantile': .3,\n",
        "                'eps': .1,\n",
        "                'damping': .9,\n",
        "                'preference': -200,\n",
        "                'n_neighbors': 10,\n",
        "                'n_clusters': 3,\n",
        "                'min_samples': 20,\n",
        "                'xi': 0.05,\n",
        "                'min_cluster_size': 0.1}\n",
        "\n",
        "# datasets = [\n",
        "#     (noisy_circles, {'damping': .77, 'preference': -240,\n",
        "#                      'quantile': .2, 'n_clusters': 2,\n",
        "#                      'min_samples': 20, 'xi': 0.25}),\n",
        "#     (noisy_moons, {'damping': .75, 'preference': -220, 'n_clusters': 2}),\n",
        "#     (varied, {'eps': .18, 'n_neighbors': 2,\n",
        "#               'min_samples': 5, 'xi': 0.035, 'min_cluster_size': .2}),\n",
        "#     (aniso, {'eps': .15, 'n_neighbors': 2,\n",
        "#              'min_samples': 20, 'xi': 0.1, 'min_cluster_size': .2}),\n",
        "#     (blobs, {}),\n",
        "#     (no_structure, {})]\n",
        "datasets = [\n",
        "    ((YS[0], None), {}),\n",
        "    ((YS[1], None), {}),\n",
        "    ((YS[2], None), {}),\n",
        "    ((YS[3], None), {}),\n",
        "    ((Y_iso, None), {}),\n",
        "    ((Y_mds, None), {}),\n",
        "    ((Y_se, None), {}),\n",
        "    ((Y_tsne, None), {})\n",
        "]\n",
        "\n",
        "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
        "    # update parameters with dataset-specific values\n",
        "    params = default_base.copy()\n",
        "    params.update(algo_params)\n",
        "\n",
        "    X, y = dataset\n",
        "\n",
        "    # normalize dataset for easier parameter selection\n",
        "    X = StandardScaler().fit_transform(X)\n",
        "\n",
        "    # estimate bandwidth for mean shift\n",
        "    bandwidth = cluster.estimate_bandwidth(X, quantile=params['quantile'])\n",
        "\n",
        "    # connectivity matrix for structured Ward\n",
        "    connectivity = kneighbors_graph(\n",
        "        X, n_neighbors=params['n_neighbors'], include_self=False)\n",
        "    # make connectivity symmetric\n",
        "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
        "\n",
        "    # ============\n",
        "    # Create cluster objects\n",
        "    # ============\n",
        "    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
        "    two_means = cluster.MiniBatchKMeans(n_clusters=params['n_clusters'])\n",
        "    ward = cluster.AgglomerativeClustering(\n",
        "        n_clusters=params['n_clusters'], linkage='ward',\n",
        "        connectivity=connectivity)\n",
        "    spectral = cluster.SpectralClustering(\n",
        "        n_clusters=params['n_clusters'], eigen_solver='arpack',\n",
        "        affinity=\"nearest_neighbors\")\n",
        "    dbscan = cluster.DBSCAN(eps=params['eps'])\n",
        "    optics = cluster.OPTICS(min_samples=params['min_samples'],\n",
        "                            xi=params['xi'],\n",
        "                            min_cluster_size=params['min_cluster_size'])\n",
        "    affinity_propagation = cluster.AffinityPropagation(\n",
        "        damping=params['damping'], preference=params['preference'])\n",
        "    average_linkage = cluster.AgglomerativeClustering(\n",
        "        linkage=\"average\", affinity=\"cityblock\",\n",
        "        n_clusters=params['n_clusters'], connectivity=connectivity)\n",
        "    birch = cluster.Birch(n_clusters=params['n_clusters'])\n",
        "    gmm = mixture.GaussianMixture(\n",
        "        n_components=params['n_clusters'], covariance_type='full')\n",
        "\n",
        "    clustering_algorithms = (\n",
        "        ('MiniBatchKMeans', two_means),\n",
        "        ('AffinityPropagation', affinity_propagation),\n",
        "        ('MeanShift', ms),\n",
        "        ('SpectralClustering', spectral),\n",
        "        ('Ward', ward),\n",
        "        ('AgglomerativeClustering', average_linkage),\n",
        "        ('DBSCAN', dbscan),\n",
        "        ('OPTICS', optics),\n",
        "        ('Birch', birch),\n",
        "        ('GaussianMixture', gmm)\n",
        "    )\n",
        "\n",
        "    for name, algorithm in clustering_algorithms:\n",
        "        t0 = time.time()\n",
        "\n",
        "        # catch warnings related to kneighbors_graph\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.filterwarnings(\n",
        "                \"ignore\",\n",
        "                message=\"the number of connected components of the \" +\n",
        "                \"connectivity matrix is [0-9]{1,2}\" +\n",
        "                \" > 1. Completing it to avoid stopping the tree early.\",\n",
        "                category=UserWarning)\n",
        "            warnings.filterwarnings(\n",
        "                \"ignore\",\n",
        "                message=\"Graph is not fully connected, spectral embedding\" +\n",
        "                \" may not work as expected.\",\n",
        "                category=UserWarning)\n",
        "            algorithm.fit(X)\n",
        "\n",
        "        t1 = time.time()\n",
        "        if hasattr(algorithm, 'labels_'):\n",
        "            y_pred = algorithm.labels_.astype(np.int)\n",
        "        else:\n",
        "            y_pred = algorithm.predict(X)\n",
        "\n",
        "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
        "        if i_dataset == 0:\n",
        "            plt.title(name, size=18)\n",
        "\n",
        "        colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n",
        "                                             '#f781bf', '#a65628', '#984ea3',\n",
        "                                             '#999999', '#e41a1c', '#dede00']),\n",
        "                                      int(max(y_pred) + 1))))\n",
        "        # add black color for outliers (if any)\n",
        "        colors = np.append(colors, [\"#000000\"])\n",
        "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
        "\n",
        "        plt.xlim(-2.5, 2.5)\n",
        "        plt.ylim(-2.5, 2.5)\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())\n",
        "#         plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
        "#                  transform=plt.gca().transAxes, size=15,\n",
        "#                  horizontalalignment='right')\n",
        "        plot_num += 1\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}